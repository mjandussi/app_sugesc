# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”‚ pages/01_Encerramento_Disponibilidades.py
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import streamlit as st
import pandas as pd
import numpy as np
import re
from core.utils import br_to_float, chunk_list, serie_6dig, convert_df_to_excel, convert_df_to_csv, convert_df_to_csv_com_zfill
from core.layout import setup_page, sidebar_menu, get_app_menu

# ConfiguraÃ§Ã£o da pÃ¡gina
setup_page(page_title="Encerramento de Disponibilidades", layout="wide", hide_default_nav=True)

# Menu lateral estruturado
sidebar_menu(get_app_menu(), use_expanders=True, expanded=False)

st.title("ğŸ§© AnÃ¡lise Para Encerramento de Disponibilidades Financeiras no SiafeRio")
st.markdown("---")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FunÃ§Ãµes EspecÃ­ficas desta PÃ¡gina
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def montar_regras_por_ug(df: pd.DataFrame, max_terms_por_expressao: int = 80) -> pd.DataFrame:
    """
    Monta regras de encerramento agrupadas por UG, ano, tipo e fonte.

    Args:
        df: DataFrame processado com dados de encerramento
        max_terms_por_expressao: NÃºmero mÃ¡ximo de termos por expressÃ£o

    Returns:
        DataFrame com regras geradas
    """
    regras = []
    gcols = ["ug", "ano_fonte", "tipo_deta", "FONTE"]

    for (ug, ano, tipo, fonte), dfg in df.groupby(gcols, dropna=False):
        dets = sorted(dfg["detalhamento"].unique().tolist())

        for parte, pedaco in enumerate(chunk_list(dets, max_terms_por_expressao), start=1):
            det_join = ",".join(pedaco)
            regra = (
                f"[IDENTIFICADOR EXERCÃCIO FONTE].[CÃ“DIGO] = {int(ano)} "
                f"e [TIPO DE DETALHAMENTO DE FONTE].[CÃ“DIGO] = {int(tipo)} "
                f"e (extrai([DETALHAMENTO DE FONTE].[CÃ“DIGO], 1, 6) pertence ({fonte}) "
                f"e nÃ£o extrai([DETALHAMENTO DE FONTE].[CÃ“DIGO], 7, 6) pertence ({det_join})) "
                f"e [UNIDADE GESTORA EMITENTE].[CÃ“DIGO] = {ug}"
            )
            regras.append({
                "ug": ug,
                "ano_fonte": int(ano),
                "tipo_deta": int(tipo),
                "FONTE": fonte,
                "quantidade_detalhamentos": len(dets),
                "parte": parte,
                "expressao": regra,
            })

    return (
        pd.DataFrame(regras)
          .sort_values(["ug", "ano_fonte", "tipo_deta", "FONTE", "parte"])
          .reset_index(drop=True)
    )


def processar_txt(raw_text: str) -> pd.DataFrame:
    """
    Processa o arquivo TXT com dados de encerramento.

    Args:
        raw_text: ConteÃºdo bruto do arquivo TXT

    Returns:
        DataFrame processado com informaÃ§Ãµes de encerramento
    """
    pat = re.compile(
        r"UG:\s*(?P<ug>\d+)\s+"
        r"Documento:\s*(?P<documento>\S+)\s+"
        r"Conta:\s*(?P<conta_codigo>\d+)\s*-\s*(?P<conta_nome>.*?)\s+"
        r"Conta corrente:\s*(?P<conta_corrente>[\d\.\-]+)\s+"
        r"Valor necessÃ¡rio:\s*(?P<valor_necessario>[\d\.\,\-]+)\s+"
        r"Valor existente:\s*(?P<valor_existente>[\d\.\,\-]+)\s+"
        r"M[eÃª]s:\s*(?P<mes>\w+)\s+"
        r"Eventos:\s*(?P<eventos>\d+)",
        flags=re.DOTALL | re.IGNORECASE,
    )

    rows = []
    for m in pat.finditer(raw_text):
        d = m.groupdict()
        d["valor_necessario"] = br_to_float(d["valor_necessario"])
        d["valor_existente"]  = br_to_float(d["valor_existente"])
        d["faltante"] = (d["valor_necessario"] or 0.0) - (d["valor_existente"] or 0.0)
        rows.append(d)

    df = pd.DataFrame(rows, columns=[
        "ug", "documento", "conta_codigo", "conta_nome", "conta_corrente",
        "valor_necessario", "valor_existente", "faltante", "mes", "eventos"
    ])

    for col in ["ug", "documento", "conta_codigo", "conta_corrente", "mes", "eventos"]:
        df[col] = df[col].astype("string")

    # Extrair colunas da conta corrente
    df = df[['ug', 'conta_codigo', 'conta_corrente']]
    parts = df["conta_corrente"].str.split(r"\.", expand=True)
    cols = ["ano_fonte", "f1", "f2", "marcador_fonte", "tipo_deta", "detalhamento"]
    parts.columns = cols[:parts.shape[1]]

    df_encerr = pd.concat([df, parts], axis=1)
    df_encerr['FONTE'] = df_encerr['f1'] + df_encerr['f2'] + df_encerr['marcador_fonte']
    df_encerr = df_encerr[['ug', 'ano_fonte', 'FONTE', 'marcador_fonte', 'tipo_deta', 'detalhamento']]

    # Padronizar com 6 dÃ­gitos
    df_encerr = df_encerr.copy()
    df_encerr['ug'] = serie_6dig(df_encerr['ug'])
    df_encerr['detalhamento'] = serie_6dig(df_encerr['detalhamento'])

    return df_encerr


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Interface do UsuÃ¡rio - ABAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

tab0, tab1 = st.tabs([
    "AnÃ¡lise Processo de Encerramento Disponibilidades",
    "AnÃ¡lise Saldos 72111 - (82114+82115)"
])

# ============================================================================
# TAB 0: ANÃLISE DE REGRAS
# ============================================================================
with tab0:
    st.header("AnÃ¡lise Erros no Processo de Encerramento das Disponibilidade e Gerador de Regras de Compatibilidade")

    # SeÃ§Ã£o de upload e configuraÃ§Ãµes
    col1, col2, col3 = st.columns([2, 1, 1])

    with col1:
        uploaded_file = st.file_uploader(
            "ğŸ“ Carregar arquivo TXT",
            type=['txt'],
            help="FaÃ§a upload do arquivo de erros (ex: erros_ug.txt)",
            key="txt_uploader"
        )

    with col2:
        max_terms = st.number_input(
            "Termos por expressÃ£o - mÃ­n 100 / mÃ¡x 400",
            min_value=100,
            max_value=400,
            value=200,
            step=20,
            help="Quantidade de detalhamentos por regra fora do intervalo"
        )

    with col3:
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("ğŸ”„ Atualizar/Resetar", help="Limpa todos os dados e reinicia a aplicaÃ§Ã£o", use_container_width=True):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()

    st.markdown("---")

    if uploaded_file is not None:
        raw_text = uploaded_file.read().decode("utf-8", errors="ignore")
        st.success(f"âœ… Arquivo '{uploaded_file.name}' carregado com sucesso!")

        if st.button("ğŸ”„ Processar Arquivo", type="primary"):
            with st.spinner("Processando dados..."):
                try:
                    df_encerr = processar_txt(raw_text)
                    st.session_state['df_encerr'] = df_encerr
                    st.session_state['raw_text'] = raw_text

                    df_regras = montar_regras_por_ug(df_encerr, max_terms_por_expressao=max_terms)
                    st.session_state['df_regras'] = df_regras

                    st.success("âœ… Processamento concluÃ­do!")
                except Exception as e:
                    st.error(f"âŒ Erro ao processar arquivo: {str(e)}")

    if 'df_encerr' in st.session_state and 'df_regras' in st.session_state:
        with st.expander("ğŸ“„ Ver ConteÃºdo do Arquivo TXT Original"):
            st.text_area(
                "ConteÃºdo bruto",
                st.session_state['raw_text'],
                height=300,
                disabled=True
            )

        with st.expander("ğŸ“Š Ver a Tabela de Erros Processada"):
            df_encerr = st.session_state['df_encerr']
            st.info(f"**Total de registros:** {len(df_encerr)}")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                ugs = ['Todos'] + sorted(df_encerr['ug'].unique().tolist())
                ug_filter = st.selectbox("Filtrar por UG", ugs, key="ug_filter_encerr")
            with col2:
                anos = ['Todos'] + sorted(df_encerr['ano_fonte'].unique().tolist())
                ano_filter = st.selectbox("Filtrar por Ano", anos, key="ano_filter_encerr")
            with col3:
                tipos = ['Todos'] + sorted(df_encerr['tipo_deta'].unique().tolist())
                tipo_filter = st.selectbox("Filtrar por Tipo Detalhamento", tipos, key="tipo_filter_encerr")
            with col4:
                fontes = ['Todos'] + sorted(df_encerr['FONTE'].unique().tolist())
                fonte_filter = st.selectbox("Filtrar por Fonte", fontes, key="fonte_filter_encerr")

            df_filtered = df_encerr.copy()
            if ug_filter != 'Todos':
                df_filtered = df_filtered[df_filtered['ug'] == ug_filter]
            if ano_filter != 'Todos':
                df_filtered = df_filtered[df_filtered['ano_fonte'] == ano_filter]
            if tipo_filter != 'Todos':
                df_filtered = df_filtered[df_filtered['tipo_deta'] == tipo_filter]
            if fonte_filter != 'Todos':
                df_filtered = df_filtered[df_filtered['FONTE'] == fonte_filter]

            st.dataframe(df_filtered, use_container_width=True, height=400)


            # Exportar Tabela Filtrada
            csv_encerr = convert_df_to_csv_com_zfill(
                df_filtered,
                zfill_map={"ug": 6, "FONTE": 6, "detalhamento": 6}
            )
            st.download_button(
                label="ğŸ“¥ Download CSV",
                data=csv_encerr,
                file_name="df_encerr.csv",
                mime="text/csv"
            )

        st.markdown("---")
        st.header("ğŸ¯ Regras Geradas")

        df_regras = st.session_state['df_regras']

        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("Total de Regras", len(df_regras))
        with col2:
            st.metric("UGs Ãšnicas", df_regras['ug'].nunique())
        with col3:
            st.metric("Anos Fontes Ãšnicos", df_regras['ano_fonte'].nunique())
        with col4:
            st.metric("Tipos de Detalh. Ãšnicos", df_regras['tipo_deta'].nunique())
        with col5:
            st.metric("Fontes Ãšnicas", df_regras['FONTE'].nunique())

        st.dataframe(df_regras, use_container_width=True, height=500)

        st.markdown("### ğŸ“¥ Exportar Regras")

        # Exportar as Regras de Compatibilidade em CSV (com padding de zeros)
        csv_regras = convert_df_to_csv_com_zfill(
            df_regras,
            zfill_map={"ug": 6, "FONTE": 6, "detalhamento": 6}
        )
        st.download_button(
            label="ğŸ“¥ Download CSV",
            data=csv_regras,
            file_name="df_regras.csv",
            mime="text/csv",
            type="primary"
        )

        with st.expander("ğŸ” Ver Detalhes de uma Regra EspecÃ­fica"):
            regra_idx = st.number_input(
                "Selecione o Ã­ndice da regra",
                min_value=0,
                max_value=len(df_regras)-1,
                value=0
            )

            if regra_idx < len(df_regras):
                regra = df_regras.iloc[regra_idx]
                st.write("**UG:**", regra['ug'])
                st.write("**Ano Fonte:**", regra['ano_fonte'])
                st.write("**Tipo Detalhamento:**", regra['tipo_deta'])
                st.write("**Fonte:**", regra['FONTE'])
                st.write("**Quantidade de Detalhamentos:**", regra['quantidade_detalhamentos'])
                st.write("**Parte:**", regra['parte'])
                st.write("**ExpressÃ£o:**")
                st.code(regra['expressao'], language="text")

    else:
        st.info("ğŸ‘† FaÃ§a upload de um arquivo TXT para comeÃ§ar a anÃ¡lise.")

        st.markdown("""
        ### ğŸ“‹ Como usar:
        1. **Gerar os Dados**: ApÃ³s o processo de encerramento, salve os erros em arquivo TXT
        2. **Upload do Arquivo**: Clique em "Browse files" e selecione o seu arquivo `.txt` com os erros
        3. **Processar**: Clique no botÃ£o "ğŸ”„ Processar Arquivo"
        4. **Visualizar Dados**: Expanda as seÃ§Ãµes para ver o DataFrame processado
        5. **Exportar Regras**: Baixe o arquivo para alimentar as Regras de Compatibilidade (pode ser em CSV ou Excel)

        ### ğŸ“Š O que faz esta aplicaÃ§Ã£o:

        - Processa arquivos TXT com dados de erros por UG
        - Extrai informaÃ§Ãµes de conta corrente, fonte e detalhamentos
        - Gera as regras de compatibilidade para o processo de encerramento automaticamente
        - Permite visualizaÃ§Ã£o e filtragem dos dados
        - Exporta resultados em mÃºltiplos formatos
        """)


# =================================================================================================
# TAB 1: ANÃLISE que apura a diferenÃ§a entre os contas-correntes das contas 72111 - (82114+82115)
# =================================================================================================
with tab1:
    st.header("ğŸ“Š AnÃ¡lise que apura a diferenÃ§a entre os contas-correntes das contas 72111 - (82114+82115)")

    uploaded_csv = st.file_uploader(
        "ğŸ“ Carregar arquivo CSV",
        type=['csv'],
        help="FaÃ§a upload do arquivo CSV com dados extraÃ­dos do Flexvision",
        key="csv_uploader"
    )

    if uploaded_csv is not None:
        try:
            # Ler CSV com separador ponto-e-vÃ­rgula
            df_csv = pd.read_csv(uploaded_csv, sep=';', encoding='latin1', dtype=str)

            # Remover espaÃ§os extras dos nomes das colunas
            df_csv.columns = df_csv.columns.str.strip()

            # Lista de colunas numÃ©ricas que devem ser convertidas
            colunas_numericas = [
                'Conta 721110101 (A)',
                'Contas 82114 (B)',
                'Contas 82115 (C)',
                'DiferenÃ§a = (A) - (B) - (C)'
            ]

            # Converter colunas numÃ©ricas do formato brasileiro para float
            for col in colunas_numericas:
                if col in df_csv.columns:
                    # Remove pontos (separador de milhar) e substitui vÃ­rgula por ponto (decimal)
                    df_csv[col] = (
                        df_csv[col]
                        .str.replace('.', '', regex=False)
                        .str.replace(',', '.', regex=False)
                        .astype(float)
                    )

            st.success(f"âœ… Arquivo '{uploaded_csv.name}' carregado com sucesso!")

            st.info(f"**Total de registros:** {len(df_csv)} | **Colunas:** {len(df_csv.columns)}")

            # OpÃ§Ã£o de filtro
            opcao_filtro = st.radio(
                "OpÃ§Ã£o de visualizaÃ§Ã£o:",
                ["Exibir completo", "Filtrar por UG"],
                horizontal=True
            )

            if opcao_filtro == "Filtrar por UG":
                if 'Unidade Gestora' in df_csv.columns:
                    ugs_disponiveis = sorted(df_csv['Unidade Gestora'].unique().tolist())
                    ug_selecionada = st.selectbox("Selecione a UG:", ugs_disponiveis)
                    df_exibir = df_csv[df_csv['Unidade Gestora'] == ug_selecionada]
                    st.info(f"**Registros filtrados:** {len(df_exibir)}")
                else:
                    st.warning("âš ï¸ Coluna 'Unidade Gestora' nÃ£o encontrada no arquivo.")
                    df_exibir = df_csv
            else:
                df_exibir = df_csv

            # Criar cÃ³pia para exibiÃ§Ã£o formatada
            df_exibir_formatado = df_exibir.copy()

            # Formatar colunas numÃ©ricas para padrÃ£o brasileiro na exibiÃ§Ã£o
            for col in colunas_numericas:
                if col in df_exibir_formatado.columns:
                    # Formatar: separador de milhar (.) e decimal (,) com 2 casas decimais
                    df_exibir_formatado[col] = df_exibir_formatado[col].apply(
                        lambda x: f"{x:,.2f}".replace(',', 'X').replace('.', ',').replace('X', '.') if pd.notna(x) else ''
                    )

            # Exibir dataframe formatado
            st.dataframe(df_exibir_formatado, use_container_width=True, height=500)

            # BotÃµes de download
            st.markdown("### ğŸ“¥ Exportar Dados")
            col1, col2 = st.columns(2)

            with col1:
                csv_data = convert_df_to_csv(df_exibir)
                st.download_button(
                    label="ğŸ“¥ Download CSV",
                    data=csv_data,
                    file_name="dados_filtrados.csv",
                    mime="text/csv",
                    type="primary"
                )

            with col2:
                excel_data = convert_df_to_excel(df_exibir)
                st.download_button(
                    label="ğŸ“¥ Download Excel",
                    data=excel_data,
                    file_name="dados_filtrados.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )

        except Exception as e:
            st.error(f"âŒ Erro ao processar arquivo CSV: {str(e)}")

    else:
        st.info("ğŸ‘† FaÃ§a upload de um arquivo CSV (extraÃ­do do Flex) para comeÃ§ar a anÃ¡lise.")

        st.markdown("""
        ### Como usar:
        1. Acesse o **Flexvision**, depois acesse a pasta de "Outros usuÃ¡rios" e pesquise pelo nÃºmero da Consulta: `077683`
        2. Nome da Consulta: `DiferenÃ§as entre C/C 72111 x 82114 e 82115`
        3. Gere a consulta e **exporte para CSV**
        4. FaÃ§a o **upload do arquivo CSV** acima
        5. **Escolher VisualizaÃ§Ã£o**: Selecione entre exibir todos os dados ou filtrar por UG
        6. **Filtrar (opcional)**: Se escolher filtrar, selecione a UG desejada
        7. **Exportar**: Baixe os dados filtrados em CSV ou Excel

        ### Recursos:

        - VisualizaÃ§Ã£o completa ou filtrada por Unidade Gestora
        - ExportaÃ§Ã£o em mÃºltiplos formatos
        - Interface simples e intuitiva
        """)


# RodapÃ©
st.markdown("---")
st.markdown(f"""
<div style='text-align: center; color: #666;'>
    <small>APP SUGESC â€” Hub Central de AnÃ¡lises | Desenvolvido pela equipe CISSC/SUGESC/SUBCONT | Â© {pd.Timestamp.today().year}</small>
</div>
""", unsafe_allow_html=True)
